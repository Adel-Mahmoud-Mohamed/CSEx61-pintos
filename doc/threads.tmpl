             +-------------------------+
             |         CS 140          |
             | PROJECT 4: FILE SYSTEMS |
             |     DESIGN DOCUMENT     |
             +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Mahmoud Attia <es-mahmoudattia2025@alexu.edu.eg>
FirstName LastName <email@domain.example>
FirstName LastName <email@domain.example>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

this web page: https://web.stanford.edu/class/cs140/projects/pintos/pintos_2.html

                Alarm 
             ============

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to timer.c:

    struct list sleepingList;   /*  list of sleeping threads. In this list we keep the sleeping threads 
                                    ordered ascendingly according to according to the threads wakeup ticks.
                                    threads wakeup_ticks is checked after each tick in the timer_interrupt 
                                    and if it was greater than the current ticks unblock this thread and 
                                    remove it for this list */
    
Added to struct thread:
	int64_t wakeup_ticks;       /* the tick we want the thread to wakeup on*/

Added to thread.h, thread.c:
	bool minWakeUpComparison(const struct list_elem *,const struct list_elem *, void *);
                    		 /* custom comparison for the list_insert_ordered function.pass 2 list_elem to 
                             it ang git their corresponding 2 threads and compare between their wakeup_ticks, 
                             returns T if the first has wakeup_ticks smaller than the second otherwise returns 
                             false. used in the list_insert_ordered tp insert the blocked thread in the sleepingList*/

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(ticks),
>> including the effects of the timer interrupt handler.

first thing we check that the interrupt is turned on (it must be) then if ticks to sleep where smaller than or
equal to 0 then return as there is no need to sleep. Then disable interrupts and store the current interrupt level 
in the old_level enum to protect the critcal section. Sets the curr_thread wakeup_ticks to curr timer ticks + 
the passed ticks to sleep to wakeup after this ticks from now. Then use the list_insert_ordered function to add 
the current thread to the sleeping_list(sorted by the minimum wakeup time). then block the curr thread and set the 
interrupt_level to its old value as we are out the critcal section now.

The timer interrupt handler check after each system tick the threads in the sleeping list to wakeup them if needed.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

use the list_insert_ordered so that threads in the sleepingList are sorted by the minimum wakeup time so when 
checking the wakeup time of each thread if we reach to a thread whose wakeup time is greater than the current 
system ticks we break without check the rest of threads as their wakeup time is greater or equal to this thread so 
minimize time inside the interrupt handler.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

before entering the critcal section where we modify the sleeping list, block the thread, and then schedule another 
thread we disable inturrupts so no other threads can enter this critcal section and section is considered as atomic 
operation.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

as we mentioned previously we disable interrupts before calling thread_block so the timer interrupt can't be serviced 
while we are inside the timer_sleep() critical section so race condition inside timer_interrupt (where we un_block 
threads and iterate sleepingList) is avoided.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

we know that the timer_interrupt function is called after each tick so the most important thing to consider is to 
minimize the amount of time spent on this function so we used ordered list to store the blocked threads so when 
checking them to wake_up we take the minimum possible time as illustrated in A3. When we think to implement using 
a non-ordered list we through that this way want enable us to minimize time inside timer_interrupt as we would have
to check all elements in the list which will decrease the system speed.


			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to thread.c:
    struct list donateList;                 /*  the list of threads which donating their priority to the thread 
                                                which acquires the lock or resource*/

    static struct list ready_list;          /*  List of processes in THREAD_READY state, that is, processes that
                                                are ready to run but not actually running. */

Added to struct thread:

    int priority;                           /*  the current real priority of a thread not the donatedPriority. 
                                                it equals to the donatedPriority when there are no donations but 
                                                it differs when there are. */
        
    int donatedPriority;                    /*  temporary variable to save the original priority when there are 
                                                donations. used in the set priority function and is used when 
                                                donation finishes to ensure that a thread has its original priority. */
    
    bool donee;                             /*  set to true if another thread donates its priority to thread 
                                                otherwise is fale*/

    struct lock *wait_lock;                 /*  set to NULL if there is no donation otherwise points to the lock 
                                                that the thread is waiting on while donating its priority to a 
                                                lower priority thread */
    
    int nested_depth;                       /*  controls the maximum depth of nested donation (10) */

    struct donate_list;                     /*  list of the threads donating their priorities to the thread */

    struct list_elem donateelem;            /*  to point to the elements in the donate_list  */

    struct list_element readyeleme:         /*  to point to the elements in the readylist  */
    
>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

we'll try to explain it in a form of a story, suppose that we have a lock say L, and two threads are there t1, and t2 
of priority p1 and p2 respectively and p2 > p1, now t1 is aquiring L and it's granted now consider this:
thread t2 wants to aquire the lock -->	- Thread t2 wait_lock points to lock L 
					- Thread t2 is added to donate_list(list that keeps the largest priority on front) of thread t1  
					- In case of nested donations we loop through the chain changing the lock holders priorities to p2 if it's larger
					- sets the boolean donee of p1 to true to indicate that its actual priority is not the same as the effective_priority

Thread t1 wants releases the lock L --> - The thread t2-since it's supposed to be the largest p in the donate list-is poped out of the donate_list
					- after popping t2 we assign t1's effective_priority to the next highest in its donate_list if there's any
					  and if t1's donate_list is now empty we assign t1.effective_priority = t.priority

so basically, by using a donate_list for each thread and a pointer to a lock. it is ensured that every thread holds its donators,
which makes it easier to track mulitple donators and nested donation by only dereferencing wait_lock to their holders.


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
Because any thread is put into readylist or blockedlist waiting on lock_acquire, sema_up,  cond_wait , 
thread_yield and thread_unblock and this list is ordered using list_insert_ordered according to the priority.
so, Always the front of the list is the thread with biggest priority.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
let we have a lock (L), with current holder (Thread (A)) with priority p1.
There is a thread (B) with priority p2 -which p2>p1- also wants to acquire this lock.
sequence:
-->thread A is the current holder of (L).
-->thread B wants to acquire the lock (L).
-->Thread B->wait_pointer is set to (L) and thread (A)->donee is set to true refers to there is donation case.
-->Then thread (B) is inserted to donate_list of thread (A).
-->A temporary_lock pointer is initialized to lock (L).
-->Then we iterate through the threads waiting for lock (L) by derefrence wait_pointer until it becomes (NULL).
-->In each thread we encounter we change its priority to (P2) if its (priority<P2) keeping the real priority 
saved in donated priority field for each changed thread.
--> Then donate_list of the lock(L) holder thread is ordered according to priority, first thread in the list 
will be the thread with biggest priority.
-->temporary_lock pointer is set to the wait_pointer of temporary_lock holder thread.
--> Max nested level is 10.
nested level donation is handled as follows: we iterate on each thread in the chain and derefrence the threads 
in waiting on lock (Li) starting from the current holder of L0 thread.then go to the current holder of L1 thread,...etc.
giving the maximum priority of these threads to the current holder L0 thread.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.
Say we have lock L,  thread A having original priority P1 and currently acquiring Lock L, and thread B of priority P2 where P2 > P1

--> we see if thread A donate_list is empty, then its priority = the donated priority and set A->donee to false 
indicating no thread donation exist.
-->otherwise we pop the thread B(which will be the thread with highest priority) from A's donate_list, 
change thread A->donatedpriority to the biggest priority in thread A. donate_list.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

the critical section in the set priority function is when changing the priority of the current thread so we avoided
race condition in this part by disabling interrupt before entering this section and enable it after calling the 
yield function. yes we can use locks such as semaphores to handle this race condition but we used the disable 
interrupt way as it is simpller and its efficient and enouph as PINTOS works on only one processor.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

since donate_list of the thread is ordered according to priorities then the schedular can only pick the top of 
the list without having to iterate through the whole list and that contributes in keeping the schedular cycles 
as small as possible. if we let the lists unordered this will lead to needing to iterate on the list which will
take more cycles.

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct recentCpuFixed
        Includes an integer field that is dealt as fixed point
        Represents the time taken by each running or waiting thread
        It's used in thread struct
        Declaration: struct recentCpuFixed recentCpu;

struct niceValueFixed
        Includes an integer field
        Describes how easy the thread give up the CPU
        It's used in thread struct
        Declaration: struct niceValueFixed niceValue;

struct loadAvgFixed
        Includes an integer field that is dealt as fixed point
        Estimates the average number of threads ready to run over the past minute
        It's a glabal variable in thread.c
        Declaration: struct loadAvgFixed loadAvg;

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  63  61  59      A
 4      4   0   0  62  61  59      A
 8      8   0   0  61  61  59      B
12      8   4   0  61  60  59      A
16      12  4   0  60  60  59      B
20      12  8   0  60  59  59      A
24      16  8   0  59  59  59      C
28      16  8   4  59  59  58      B
32      16  12  4  59  58  58      A 
36      20  12  4  58  58  58      C

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

- Yes, there was an ambiguity concerning which thread to run when
- there are more than one thread having the maximum priority.
- This is solved by choosing the last thread with maximum priority to run
- and place the previous running thread in its appropriate place in the
- descendingly ordered ready_list.
- Yes, this matches the behavior of our scheduler due to ordering
- and the the selected thread to run still has the maximum priority.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

- By disabling the interrupts before changing the priority of the current running thread
- as it represents a critical section, and then enabling it after performing "yield"
- when there exists a thread with higher priority in the ready_list.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

Advantages: - as the ready_list is always sorted descindingly, in upadtePriorities function
              choosing the next thread to run is fast
	        - calculations are quite fast
Disadvantages: - it takes a long time to sort the ready_list after updating priorities
		       - updating the priorities itself requires looping through all threads, and
                 this is repeated every tick, second, and time slice

- If we had extra time:
        we would have thought of another method such as deriving estimates for the priorities after
        a certain period of time or updating the priorities, recent_cpu and load Averages in batches


>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

- Our implementation is fast and easy using the binary shift operator
- This implementation is reusable and provides encapsulation

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
